{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark\\\\spark-3.1.1-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()     #기존에 열려있는 session가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-280b431848fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# table 생성 30초~40초\n",
    "\n",
    "\n",
    "\n",
    "def CreateEveryday():\n",
    "    oil_df = spark.read.orc(\"../orc/oil\") # 매일 업데이트 ******\n",
    "\n",
    "    Pyeongtaek_df = spark.read.orc(\"../orc/main_area_weather/4122000000\") #평택, 오이 (일조량 0)     # 매일 업데이트 *******\n",
    "    Anseong_df = spark.read.orc(\"../orc/main_area_weather/4155000000\") #안성, 대파     # 매일 업데이트 *******\n",
    "    Chuncheon_df = spark.read.orc(\"../orc/main_area_weather/4211000000\") #춘천, 호박     # 매일 업데이트 *******\n",
    "    Jeongeup_df = spark.read.orc(\"../orc/main_area_weather/4518000000\") #정읍, 쌀     # 매일 업데이트 *******\n",
    "    Hampyeong_df = spark.read.orc(\"../orc/main_area_weather/4686000000\") #함평, 양파     # 매일 업데이트 *******\n",
    "    Sangju_df = spark.read.orc(\"../orc/main_area_weather/4725000000\") #상주, 오이     # 매일 업데이트 *******\n",
    "    Gimhae_df = spark.read.orc(\"../orc/main_area_weather/4825000000\") #김해, 대파     # 매일 업데이트 *******\n",
    "    Hamyang_df = spark.read.orc(\"../orc/main_area_weather/4887000000\") #함양, 양파     # 매일 업데이트 *******\n",
    "\n",
    "    price_df = spark.read.orc([\"../orc/price/KamisDailyPrice_1\", \"../orc/price/KamisDailyPrice_2\", \"../orc/price/KamisDailyPrice_3\"]) # 매일 업데이트 ********\n",
    "\n",
    "\n",
    "    # 유가 table\n",
    "    oil_df.createOrReplaceTempView(\"oil\")\n",
    "    spark.sql(\"CACHE TABLE oil\") \n",
    "    print(\"table oil done\")\n",
    "\n",
    "    # 날씨 table\n",
    "    Pyeongtaek_df.createOrReplaceTempView(\"PyeongtaekWeather\")\n",
    "    spark.sql(\"CACHE TABLE PyeongtaekWeather\")\n",
    "    print(\"table PyeongtaekWeather done\")\n",
    "    Anseong_df.createOrReplaceTempView(\"AnseongWeather\")\n",
    "    spark.sql(\"CACHE TABLE AnseongWeather\") \n",
    "    print(\"table AnseongWeather done\")\n",
    "    Chuncheon_df.createOrReplaceTempView(\"ChuncheonWeather\")\n",
    "    spark.sql(\"CACHE TABLE ChuncheonWeather\") \n",
    "    print(\"table ChuncheonWeather done\")\n",
    "    Jeongeup_df.createOrReplaceTempView(\"JeongeupWeather\")\n",
    "    spark.sql(\"CACHE TABLE JeongeupWeather\") \n",
    "    print(\"table JeongeupWeather done\")\n",
    "    Hampyeong_df.createOrReplaceTempView(\"HampyeongWeather\")\n",
    "    spark.sql(\"CACHE TABLE HampyeongWeather\") \n",
    "    print(\"table HampyeongWeather done\")\n",
    "    Sangju_df.createOrReplaceTempView(\"SangjuWeather\")\n",
    "    spark.sql(\"CACHE TABLE SangjuWeather\") \n",
    "    print(\"table SangjuWeather done\")\n",
    "    Gimhae_df.createOrReplaceTempView(\"GimhaeWeather\")\n",
    "    spark.sql(\"CACHE TABLE GimhaeWeather\") \n",
    "    print(\"table GimhaeWeather done\")\n",
    "    Hamyang_df.createOrReplaceTempView(\"HamyangWeather\")\n",
    "    spark.sql(\"CACHE TABLE HamyangWeather\")\n",
    "    print(\"table HamyangWeather done\")\n",
    "\n",
    "    # 가격 table         ## 시간 가장 많이 잡아먹음\n",
    "    price_df = price_df.withColumn(\"price\", price_df[\"price\"].cast(IntegerType())) # string으로 되어있는 price를 long으로 고침\n",
    "    price_df.createOrReplaceTempView(\"priceTable\")\n",
    "    spark.sql(\"CACHE TABLE priceTable\")\n",
    "    print(\"table priceTable done\")\n",
    "    print(\"=============================Create Table Everyday DONE=============================\")\n",
    "    \n",
    "    \n",
    "def CreateMonth():\n",
    "    priceIndex_df = spark.read.orc(\"../orc/priceIndex\")\n",
    "\n",
    "    # 물가 table\n",
    "    # priceIndex_df.\n",
    "    priceIndex_df.createOrReplaceTempView(\"priceIndex\")\n",
    "    spark.sql(\"CACHE TABLE priceIndex\") # 시작하기 전에 table cache하는 script 따로 만들기 -> 훨씬 빨라짐\n",
    "    print(\"table priceIndex done\")\n",
    "    print(\"=============================Create Table Month DONE=============================\")\n",
    "    \n",
    "    \n",
    "def CreateYear():\n",
    "    riceProduction_df = spark.read.orc(\"../orc/vege_production/rice\")\n",
    "    onionProduction_df = spark.read.orc(\"../orc/vege_production/onion\")\n",
    "    cucumberProduction_df = spark.read.orc(\"../orc/vege_production/cucumber\")\n",
    "    greenOnionProduction_df = spark.read.orc(\"../orc/vege_production/green_onion\")\n",
    "    pumpkinProduction_df = spark.read.orc(\"../orc/vege_production/pumpkin\")\n",
    "\n",
    "\n",
    "    # 생산량 table\n",
    "    riceProduction_df.createOrReplaceTempView(\"riceProduction\")\n",
    "    spark.sql(\"CACHE TABLE riceProduction\")\n",
    "    print(\"table riceProduction done\")\n",
    "    onionProduction_df.createOrReplaceTempView(\"onionProduction\")\n",
    "    spark.sql(\"CACHE TABLE onionProduction\")\n",
    "    print(\"table onionProduction done\")\n",
    "    cucumberProduction_df.createOrReplaceTempView(\"cucumberProduction\")\n",
    "    spark.sql(\"CACHE TABLE cucumberProduction\") \n",
    "    print(\"table cucumberProduction done\")\n",
    "    greenOnionProduction_df.createOrReplaceTempView(\"greenOnionProduction\")\n",
    "    spark.sql(\"CACHE TABLE greenOnionProduction\") \n",
    "    print(\"table greenOnionProduction done\")\n",
    "    pumpkinProduction_df.createOrReplaceTempView(\"pumpkinProduction\")\n",
    "    spark.sql(\"CACHE TABLE pumpkinProduction\") \n",
    "    print(\"table pumpkinProduction done\")\n",
    "    print(\"=============================Create Table Year DONE=============================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
