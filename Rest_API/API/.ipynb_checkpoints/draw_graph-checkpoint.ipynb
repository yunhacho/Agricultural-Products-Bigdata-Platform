{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark\\\\spark-3.1.1-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()     #기존에 열려있는 session가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################### 테스트 및 create table에서 table가져오기 ###################################\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as func\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_dict = {'오이':[['취청(50개)','가시계통(1kg)','다다기계통(100개)'],['중품','상품']],\n",
    "              '양파':[['햇양파(1kg)','양파(1kg)','수입(1kg)'],['중품','상품']],\n",
    "              '파':[['대파(1kg)','쪽파(1kg)'],['중품','상품']],\n",
    "              '호박':[['애호박(20개)','쥬키니(1kg)'],['중품','상품']],\n",
    "              '쌀':[['일반계(1kg)','햇일반계(1kg)'],['중품','상품']]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_avgPrice_graph_dict = {'오이':{'취청(50개)':{'중품':[],'상품':[]}, '가시계통(1kg)':{'중품':[],'상품':[]}, '다다기계통(100개)':{'중품':[],'상품':[]}},\n",
    "                           '양파':{'햇양파(1kg)':{'중품':[],'상품':[]},'양파(1kg)':{'중품':[],'상품':[]},'수입(1kg)':{'중품':[],'상품':[]}},\n",
    "                           '파':{'대파(1kg)':{'중품':[],'상품':[]}, '쪽파(1kg)':{'중품':[],'상품':[]}},\n",
    "                           '호박':{'애호박(20개)':{'중품':[],'상품':[]}, '쥬키니(1kg)':{'중품':[],'상품':[]}},\n",
    "                           '쌀': {'일반계(1kg)':{'중품':[],'상품':[]}, '햇일반계(1kg)':{'중품':[],'상품':[]}}}\n",
    "\n",
    "### 그래프 미리 만들어 놓기\n",
    "####################### 유가별 price 변동 그래프 (x, y) 좌표 x:유가 , y:price #######################\n",
    "\n",
    "def oil_avgPrice(item, kind, rank):\n",
    "    if oil_avgPrice_graph_dict[item][kind][rank]==[]:\n",
    "        query = \"SELECT A.`평균`,AVG(A.`price`) \\\n",
    "            FROM (\\\n",
    "            SELECT oil.`평균`,oil.`날짜`,priceTable.price \\\n",
    "            FROM oil JOIN priceTable ON oil.`날짜`=priceTable.timestamp \\\n",
    "            WHERE priceTable.item_name='{0}' AND priceTable.rank='{2}' AND priceTable.kind_name='{1}' AND priceTable.price NOT IN ('-', '0') \\\n",
    "            ORDER BY oil.`날짜` ASC\\\n",
    "            ) A \\\n",
    "            GROUP BY A.`평균` \\\n",
    "            ORDER BY A.`평균` ASC\"\n",
    "            \n",
    "        oil_avgPrice_df = spark.sql(query.format(item, kind, rank))\n",
    "\n",
    "        map_datas = map(lambda row: row.asDict(), oil_avgPrice_df.collect()) # dataframe을 map으로 바꾸기 (df.colloect()로 dataframe을 list화 한다)\n",
    "        graph_datas = list(map_datas) # map을 list로 바꾸기\n",
    "\n",
    "        oil_avgPrice_graph_dict[item][kind][rank] = graph_datas\n",
    "        \n",
    "    return oil_avgPrice_graph_dict[item][kind][rank]\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_production_area_price_graph_dict = {'오이':{'취청(50개)':{'중품':[],'상품':[]}, '가시계통(1kg)':{'중품':[],'상품':[]}, '다다기계통(100개)':{'중품':[],'상품':[]}},\n",
    "                           '양파':{'햇양파(1kg)':{'중품':[],'상품':[]},'양파(1kg)':{'중품':[],'상품':[]},'수입(1kg)':{'중품':[],'상품':[]}},\n",
    "                           '파':{'대파(1kg)':{'중품':[],'상품':[]}, '쪽파(1kg)':{'중품':[],'상품':[]}},\n",
    "                           '호박':{'애호박(20개)':{'중품':[],'상품':[]}, '쥬키니(1kg)':{'중품':[],'상품':[]}},\n",
    "                           '쌀': {'일반계(1kg)':{'중품':[],'상품':[]}, '햇일반계(1kg)':{'중품':[],'상품':[]}}}\n",
    "\n",
    "production_dict = {'오이':'cucumberProduction', '양파':'onionProduction', '파':'greenOnionProduction', '호박':'pumpkinProduction', '쌀':'riceProduction'}\n",
    "\n",
    "### 그래프 미리 만들어 놓기\n",
    "####################### 연도에따른 생산량, 면적, price평균 #######################\n",
    "\n",
    "def production_area_price(item, kind, rank):\n",
    "    if year_production_area_price_graph_dict[item][kind][rank]==[]:\n",
    "        query = \"SELECT {3}.`면적`,{3}.`생산량`,A.`avg(price)`,A.`연도` \\\n",
    "            FROM (\\\n",
    "            SELECT AVG(price), YEAR(timestamp) AS `연도` \\\n",
    "            FROM priceTable WHERE item_name='{0}' AND rank='{2}' AND kind_name='{1}' AND price NOT IN ('-') AND timestamp NOT IN ('-') \\\n",
    "            GROUP BY YEAR(timestamp) \\\n",
    "            ) A JOIN {3} ON A.`연도`={3}.`연도` \\\n",
    "            ORDER BY A.`연도` ASC\"\n",
    "\n",
    "        production_area_df = spark.sql(query.format(item, kind, rank, production_dict[item]))\n",
    "\n",
    "        map_datas = map(lambda row: row.asDict(), production_area_df.collect()) # dataframe을 map으로 바꾸기 (df.colloect()로 dataframe을 list화 한다)\n",
    "        graph_datas = list(map_datas) # map을 list로 바꾸기\n",
    "\n",
    "        year_production_area_price_graph_dict[item][kind][rank] = graph_datas\n",
    "        \n",
    "    return year_production_area_price_graph_dict[item][kind][rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_element_list = ['dayAvgTa', 'dayAvgRhm', 'daySumRn', 'dayAvgWs', 'daySumSs']\n",
    "## 기온, 습도, 강수량, 풍량, 일조량\n",
    "\n",
    "weather_avgPrice_graph_dict = {'오이':{'취청(50개)':{'중품':{},'상품':{}}, '가시계통(1kg)':{'중품':{},'상품':{}}, '다다기계통(100개)':{'중품':{},'상품':{}}},\n",
    "                           '양파':{'햇양파(1kg)':{'중품':{},'상품':{}},'양파(1kg)':{'중품':{},'상품':{}},'수입(1kg)':{'중품':{},'상품':{}}},\n",
    "                           '파':{'대파(1kg)':{'중품':{},'상품':{}}, '쪽파(1kg)':{'중품':{},'상품':{}}},\n",
    "                           '호박':{'애호박(20개)':{'중품':{},'상품':{}}, '쥬키니(1kg)':{'중품':{},'상품':{}}},\n",
    "                           '쌀': {'일반계(1kg)':{'중품':{},'상품':{}}, '햇일반계(1kg)':{'중품':{},'상품':{}}}}\n",
    "\n",
    "for item in crops_dict.keys():\n",
    "    for kind in crops_dict[item][0]:\n",
    "        for rank in crops_dict[item][1]:\n",
    "            weather_avgPrice_graph_dict[item][kind][rank]={i:[] for i in weather_element_list}\n",
    "\n",
    "area_dict = {'오이':'PyeongtaekWeather', '양파':'HampyeongWeather', '파':'AnseongWeather', '호박':'ChuncheonWeather', '쌀':'JeongeupWeather'}\n",
    "\n",
    "\n",
    "####################### 평균 기온 및 습도 등에 따른 price 변동 그래프 (x, y) #######################\n",
    "def weather_avgPrice(item, kind, rank, element):\n",
    "    if weather_avgPrice_graph_dict[item][kind][rank][element]==[]:\n",
    "        query = \"SELECT A.`{3}`,AVG(A.`price`) \\\n",
    "        FROM (\\\n",
    "        SELECT {4}.{3},priceTable.price,priceTable.timestamp \\\n",
    "        FROM {4} JOIN priceTable \\\n",
    "        ON {4}.date==priceTable.timestamp \\\n",
    "        WHERE priceTable.item_name='{0}' AND priceTable.rank='{2}' AND priceTable.kind_name='{1}' AND priceTable.price NOT IN ('-') \\\n",
    "        ) A \\\n",
    "        GROUP BY A.`{3}` \\\n",
    "        ORDER BY A.`{3}` ASC\"\n",
    "\n",
    "        weather_df = spark.sql(query.format(item, kind, rank, element, area_dict[item]))\n",
    "\n",
    "        map_datas = map(lambda row: row.asDict(), weather_df.collect()) # dataframe을 map으로 바꾸기 (df.colloect()로 dataframe을 list화 한다)\n",
    "        graph_datas = list(map_datas) # map을 list로 바꾸기\n",
    "        \n",
    "        weather_avgPrice_graph_dict[item][kind][rank][element] = graph_datas\n",
    "        \n",
    "    return weather_avgPrice_graph_dict[item][kind][rank][element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "priceIndex_element_list = ['곡물및식량작물', '채소및과실', '식료품', '음료품', '비료및농약', '농업및건설용기계', '기타운송장비', '전력가스및증기', '수도폐기물처리및재활용서비스', '음식점및숙박서비스', '장비용품및지식재산권임대']\n",
    "\n",
    "\n",
    "priceIndex_avgPrice_graph_dict = {'오이':{'취청(50개)':{'중품':{},'상품':{}}, '가시계통(1kg)':{'중품':{},'상품':{}}, '다다기계통(100개)':{'중품':{},'상품':{}}},\n",
    "                           '양파':{'햇양파(1kg)':{'중품':{},'상품':{}},'양파(1kg)':{'중품':{},'상품':{}},'수입(1kg)':{'중품':{},'상품':{}}},\n",
    "                           '파':{'대파(1kg)':{'중품':{},'상품':{}}, '쪽파(1kg)':{'중품':{},'상품':{}}},\n",
    "                           '호박':{'애호박(20개)':{'중품':{},'상품':{}}, '쥬키니(1kg)':{'중품':{},'상품':{}}},\n",
    "                           '쌀': {'일반계(1kg)':{'중품':{},'상품':{}}, '햇일반계(1kg)':{'중품':{},'상품':{}}}}\n",
    "\n",
    "\n",
    "for item in crops_dict.keys():\n",
    "    for kind in crops_dict[item][0]:\n",
    "        for rank in crops_dict[item][1]:\n",
    "            priceIndex_avgPrice_graph_dict[item][kind][rank]={i:[] for i in priceIndex_element_list}\n",
    "            \n",
    "\n",
    "### 그래프 미리 만들어 놓기\n",
    "####################### 곡물및식량물가에 따른 price 변동 그래프 (x, y) 좌표 x:물가 , y:price #######################\n",
    "def priceIndex_avgPrice(item, kind, rank, element):\n",
    "    if priceIndex_avgPrice_graph_dict[item][kind][rank][element]==[]:\n",
    "        query = \"SELECT priceIndex.`{3}`,priceTable.price,priceTable.timestamp\\\n",
    "                    FROM priceIndex RIGHT JOIN priceTable\\\n",
    "                    ON priceIndex.`날짜`==priceTable.timestamp\\\n",
    "                    WHERE priceTable.item_name='{0}' AND priceTable.rank='{2}' AND priceTable.kind_name='{1}' AND priceTable.timestamp NOT IN ('-')\"\n",
    "\n",
    "        grainFood_df = spark.sql(query.format(item,kind,rank,element))\n",
    "        grainFood_df = grainFood_df.withColumn(element, func.last(element, True).over(Window.partitionBy(func.month('timestamp')).orderBy('timestamp').rowsBetween(-sys.maxsize, 0))).orderBy(grainFood_df.timestamp.asc()).na.drop(subset=[\"price\"])\n",
    "\n",
    "\n",
    "        grainFood_df = grainFood_df.groupBy(element).agg(func.avg('price')).sort(func.asc(element)).na.drop(subset=[element])\n",
    "\n",
    "        # grainFood_df.show()\n",
    "\n",
    "\n",
    "        map_datas = map(lambda row: row.asDict(), grainFood_df.collect()) # dataframe을 map으로 바꾸기 (df.colloect()로 dataframe을 list화 한다)\n",
    "        graph_datas = list(map_datas) # map을 list로 바꾸기\n",
    "        \n",
    "        priceIndex_avgPrice_graph_dict[item][kind][rank][element] = graph_datas\n",
    "\n",
    "    return priceIndex_avgPrice_graph_dict[item][kind][rank][element]\n",
    "\n",
    "\n",
    "## test ##\n",
    "def clean_avgPrice(item, kind, rank, element):\n",
    "    if priceIndex_avgPrice_graph_dict[item][kind][rank][element]!=[]:\n",
    "        priceIndex_avgPrice_graph_dict[item][kind][rank][element] = []\n",
    "    if weather_avgPrice_graph_dict[item][kind][rank][element]!=[]:\n",
    "        weather_avgPrice_graph_dict[item][kind][rank][element] = []\n",
    "    else:\n",
    "        print(\"empty!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################### 1년에 한번씩 갱신 ###################################\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
